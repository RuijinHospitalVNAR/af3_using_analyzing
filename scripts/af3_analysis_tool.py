#!/usr/bin/env python3
"""
AlphaFold3 æ‰¹é‡åˆ†æå·¥å…·
========================
ç»Ÿä¸€å·¥å…·ç”¨äºæ‰¹é‡å¤„ç† AlphaFold3 é¢„æµ‹ç»“æœï¼ŒåŒ…æ‹¬ï¼š
1. pLDDT å€¼æå–ï¼ˆå±€éƒ¨ç»“æ„è´¨é‡ï¼‰
2. PTM/iPTM å€¼æå–ï¼ˆå…¨å±€ç»“æ„è´¨é‡ï¼‰
3. ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
    python af3_analysis_tool.py --input_dir /path/to/af3_results --output_dir /path/to/output

ç¤ºä¾‹:
    python af3_analysis_tool.py --input_dir ./results --output_dir ./analysis --verbose
"""

import os
import sys
import csv
import json
import logging
import argparse
from pathlib import Path
from typing import Optional, List, Tuple, Dict, Any

try:
    from Bio.PDB import PDBParser, MMCIFParser
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° Biopython åº“")
    print("è¯·è¿è¡Œ: pip install biopython")
    sys.exit(1)


def setup_logging(verbose: bool = False):
    """é…ç½®æ—¥å¿—"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


def calculate_average_plddt(structure_file: str) -> Optional[float]:
    """
    è®¡ç®—å•ä¸ªç»“æ„æ–‡ä»¶ï¼ˆPDB æˆ– CIFï¼‰çš„å¹³å‡ pLDDT
    
    Args:
        structure_file: ç»“æ„æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .pdb å’Œ .cif æ ¼å¼ï¼‰
        
    Returns:
        å¹³å‡ pLDDT å€¼ï¼Œå¦‚æœè®¡ç®—å¤±è´¥åˆ™è¿”å› None
    """
    try:
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åˆé€‚çš„è§£æå™¨
        file_ext = os.path.splitext(structure_file)[1].lower()
        
        if file_ext == '.cif':
            parser = MMCIFParser(QUIET=True)
            logging.debug(f"ä½¿ç”¨ MMCIFParser è§£æ {structure_file}")
        elif file_ext == '.pdb':
            parser = PDBParser(QUIET=True)
            logging.debug(f"ä½¿ç”¨ PDBParser è§£æ {structure_file}")
        else:
            logging.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
            return None
        
        structure = parser.get_structure("AF3_model", structure_file)
        plddt_scores = []

        for model in structure:
            for chain in model:
                for residue in chain:
                    # æ›´ä¸¥æ ¼çš„ CA åŸå­æ£€æŸ¥
                    try:
                        ca_atom = residue["CA"]
                        plddt = ca_atom.bfactor
                        plddt_scores.append(plddt)
                    except KeyError:
                        # æŸäº›æ®‹åŸºå¯èƒ½æ²¡æœ‰ CA åŸå­ï¼ˆå¦‚æ°´åˆ†å­ï¼‰
                        continue

        if not plddt_scores:
            logging.warning(f"æ–‡ä»¶ {structure_file} ä¸­æœªæ‰¾åˆ°ä»»ä½• CA åŸå­")
            return None
            
        avg_plddt = sum(plddt_scores) / len(plddt_scores)
        logging.debug(f"æ–‡ä»¶ {structure_file} åŒ…å« {len(plddt_scores)} ä¸ª CA åŸå­")
        return avg_plddt
        
    except Exception as e:
        logging.error(f"è§£æç»“æ„æ–‡ä»¶ {structure_file} æ—¶å‡ºé”™: {e}")
        return None


def find_best_model_file(folder_path: str) -> Optional[str]:
    """
    è¿”å›æŒ‡å®š AlphaFold3 è¾“å‡ºç›®å½•ä¸­ä¸€çº§ç›®å½•ä¸‹çš„æœ€ä½³ç»“æ„æ–‡ä»¶è·¯å¾„
    
    æ”¯æŒæ ¼å¼ï¼š.pdb, .cif
    ä¼˜å…ˆçº§ï¼šCIF > PDBï¼ŒåŒ…å« 'model' çš„æ–‡ä»¶ä¼˜å…ˆ
    """
    try:
        # æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„ç»“æ„æ–‡ä»¶
        all_files = os.listdir(folder_path)
        structure_files = [f for f in all_files 
                          if (f.endswith(".cif") or f.endswith(".pdb")) 
                          and os.path.isfile(os.path.join(folder_path, f))]
        
        if not structure_files:
            return None
        
        # ä¼˜å…ˆé€‰æ‹© CIF æ–‡ä»¶ï¼ˆAlphaFold3 ä¸»è¦è¾“å‡ºæ ¼å¼ï¼‰
        cif_files = [f for f in structure_files if f.endswith(".cif")]
        pdb_files = [f for f in structure_files if f.endswith(".pdb")]
        
        selected_file = None
        
        # å…ˆå°è¯• CIF æ–‡ä»¶
        if cif_files:
            model_cif = [f for f in cif_files if 'model' in f.lower()]
            if model_cif:
                model_cif.sort()
                selected_file = model_cif[0]
            else:
                cif_files.sort()
                selected_file = cif_files[0]
        # å†å°è¯• PDB æ–‡ä»¶
        elif pdb_files:
            model_pdb = [f for f in pdb_files if 'model' in f.lower()]
            if model_pdb:
                model_pdb.sort()
                selected_file = model_pdb[0]
            else:
                pdb_files.sort()
                selected_file = pdb_files[0]
        
        if selected_file:
            full_path = os.path.join(folder_path, selected_file)
            logging.debug(f"é€‰æ‹©ç»“æ„æ–‡ä»¶: {selected_file}")
            return full_path
        
        return None
        
    except Exception as e:
        logging.error(f"æ‰«ææ–‡ä»¶å¤¹ {folder_path} æ—¶å‡ºé”™: {e}")
        return None


def extract_confidence_from_json(
    json_file: str, 
    fields: List[str] = None
) -> Optional[Dict[str, Any]]:
    """
    ä» summary_confidences.json æ–‡ä»¶ä¸­æå–ç½®ä¿¡åº¦æŒ‡æ ‡
    
    Args:
        json_file: JSON æ–‡ä»¶è·¯å¾„
        fields: è¦æå–çš„å­—æ®µåˆ—è¡¨ï¼Œé»˜è®¤ä¸º ['ptm']
        
    Returns:
        åŒ…å«æå–å­—æ®µçš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
    """
    if fields is None:
        fields = ['ptm']
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        results = {}
        for field in fields:
            value = data.get(field, None)
            results[field] = value
            
        logging.debug(f"æˆåŠŸæå–å­—æ®µ: {results}")
        return results
        
    except json.JSONDecodeError as e:
        logging.error(f"JSON è§£æé”™è¯¯ {json_file}: {e}")
        return None
    except FileNotFoundError:
        logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return None
    except Exception as e:
        logging.error(f"è¯»å–æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
        return None


def find_summary_json(folder_path: str, filename: str = "summary_confidences.json") -> Optional[str]:
    """
    åœ¨æŒ‡å®šæ–‡ä»¶å¤¹çš„ä¸€çº§ç›®å½•ä¸­æŸ¥æ‰¾ summary_confidences.json æ–‡ä»¶
    æ”¯æŒå¸¦å‰ç¼€çš„æ–‡ä»¶å
    """
    try:
        # å…ˆæŸ¥æ‰¾æ ‡å‡†æ–‡ä»¶å
        json_file = os.path.join(folder_path, filename)
        if os.path.isfile(json_file):
            logging.debug(f"æ‰¾åˆ°æ ‡å‡†æ–‡ä»¶: {json_file}")
            return json_file
        
        # æŸ¥æ‰¾å¸¦å‰ç¼€çš„æ–‡ä»¶åï¼ˆä»¥ _summary_confidences.json ç»“å°¾ï¼‰
        for file in os.listdir(folder_path):
            if file.endswith("_summary_confidences.json") or file.endswith("summary_confidences.json"):
                json_file = os.path.join(folder_path, file)
                if os.path.isfile(json_file):
                    logging.debug(f"æ‰¾åˆ°å¸¦å‰ç¼€çš„æ–‡ä»¶: {json_file}")
                    return json_file
        
        logging.debug(f"æœªæ‰¾åˆ° summary_confidences æ–‡ä»¶åœ¨: {folder_path}")
        return None
        
    except Exception as e:
        logging.error(f"æ‰«ææ–‡ä»¶å¤¹ {folder_path} æ—¶å‡ºé”™: {e}")
        return None


def analyze_af3_results(
    main_output_dir: str, 
    output_dir: str,
    fields: List[str] = None,
    verbose: bool = False
) -> Dict[str, Any]:
    """
    ç»¼åˆåˆ†æ AlphaFold3 ç»“æœ
    
    Args:
        main_output_dir: AF3 ä¸»è¾“å‡ºç›®å½•
        output_dir: åˆ†æç»“æœè¾“å‡ºç›®å½•
        fields: è¦æå–çš„ç½®ä¿¡åº¦å­—æ®µ
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
        
    Returns:
        åˆ†æç»“æœç»Ÿè®¡
    """
    if fields is None:
        fields = ['ptm', 'iptm', 'ranking_score']
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.isdir(main_output_dir):
        logging.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {main_output_dir}")
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    results = {
        'plddt_data': [],
        'confidence_data': [],
        'errors': []
    }
    
    try:
        subdirs = [d for d in os.listdir(main_output_dir)
                   if os.path.isdir(os.path.join(main_output_dir, d))]
    except Exception as e:
        logging.error(f"æ— æ³•è¯»å–ç›®å½• {main_output_dir}: {e}")
        sys.exit(1)
    
    if not subdirs:
        logging.warning(f"ç›®å½• {main_output_dir} ä¸­æ²¡æœ‰å­æ–‡ä»¶å¤¹")
        return results

    print(f"ğŸ§­ æ£€æµ‹åˆ° {len(subdirs)} ä¸ªé¢„æµ‹ç»“æœæ–‡ä»¶å¤¹ã€‚æ­£åœ¨åˆ†æ...\n")
    print(f"ğŸ“‹ æå–å­—æ®µ: {', '.join(fields)}\n")

    for i, subdir in enumerate(sorted(subdirs), 1):
        subdir_path = os.path.join(main_output_dir, subdir)
        print(f"[{i}/{len(subdirs)}] å¤„ç†: {subdir}")
        
        # æå– pLDDT
        structure_file = find_best_model_file(subdir_path)
        avg_plddt = None
        if structure_file:
            file_ext = os.path.splitext(structure_file)[1]
            avg_plddt = calculate_average_plddt(structure_file)
            if avg_plddt is not None:
                print(f"  âœ… å¹³å‡ pLDDT: {avg_plddt:.2f} (æ ¼å¼: {file_ext})")
                results['plddt_data'].append((subdir, avg_plddt))
            else:
                print(f"  âš ï¸  æ— æœ‰æ•ˆ pLDDT æ•°æ®")
                results['errors'].append(f"{subdir}: pLDDTæå–å¤±è´¥")
        else:
            print(f"  âš ï¸  æœªæ‰¾åˆ°ç»“æ„æ–‡ä»¶ (PDB/CIF)")
            results['errors'].append(f"{subdir}: æœªæ‰¾åˆ°ç»“æ„æ–‡ä»¶")
        
        # æå–ç½®ä¿¡åº¦æŒ‡æ ‡
        json_file = find_summary_json(subdir_path)
        if json_file:
            confidence_data = extract_confidence_from_json(json_file, fields)
            if confidence_data and any(v is not None for v in confidence_data.values()):
                # æ„å»ºè¾“å‡ºè¡Œï¼šæ ·æœ¬å + å„ä¸ªå­—æ®µçš„å€¼
                row = [subdir] + [confidence_data.get(field) for field in fields]
                results['confidence_data'].append(tuple(row))
                
                # å‹å¥½çš„è¾“å‡ºæ˜¾ç¤º
                display_values = [f"{field}={confidence_data.get(field):.4f}" 
                                 if confidence_data.get(field) is not None 
                                 else f"{field}=N/A" 
                                 for field in fields]
                print(f"  âœ… {', '.join(display_values)}")
            else:
                print(f"  âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆç½®ä¿¡åº¦æ•°æ®")
                results['errors'].append(f"{subdir}: ç½®ä¿¡åº¦æå–å¤±è´¥")
        else:
            print(f"  âš ï¸  æœªæ‰¾åˆ° summary_confidences.json æ–‡ä»¶")
            results['errors'].append(f"{subdir}: æœªæ‰¾åˆ°ç½®ä¿¡åº¦æ–‡ä»¶")

    return results


def save_results(results: Dict[str, Any], output_dir: str, fields: List[str]):
    """ä¿å­˜åˆ†æç»“æœåˆ°CSVæ–‡ä»¶"""
    
    # ä¿å­˜ pLDDT ç»“æœ
    plddt_csv = os.path.join(output_dir, "plddt_scores.csv")
    with open(plddt_csv, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["Sample", "Average_pLDDT"])
        writer.writerows(results['plddt_data'])
    
    # ä¿å­˜ç½®ä¿¡åº¦ç»“æœ
    confidence_csv = os.path.join(output_dir, "confidence_scores.csv")
    with open(confidence_csv, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        header = ["Sample"] + [field.upper() for field in fields]
        writer.writerow(header)
        writer.writerows(results['confidence_data'])
    
    # åˆå¹¶æ•°æ®
    combined_csv = os.path.join(output_dir, "combined_scores.csv")
    merge_data(results['plddt_data'], results['confidence_data'], fields, combined_csv)
    
    print(f"\nğŸ“Š å·²ç”Ÿæˆç»“æœæ–‡ä»¶:")
    print(f"  ğŸ“Š {plddt_csv}")
    print(f"  ğŸ“Š {confidence_csv}")
    print(f"  ğŸ“Š {combined_csv}")
    print(f"âœ… æˆåŠŸåˆ†æ: {len(results['plddt_data'])} ä¸ªæ ·æœ¬")
    
    if results['errors']:
        print(f"âš ï¸  å¤±è´¥/è·³è¿‡: {len(results['errors'])} ä¸ªæ ·æœ¬")


def merge_data(plddt_data: List[Tuple], confidence_data: List[Tuple], fields: List[str], output_file: str):
    """åˆå¹¶ pLDDT å’Œç½®ä¿¡åº¦æ•°æ®"""
    
    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
    plddt_dict = {row[0]: row[1] for row in plddt_data}
    confidence_dict = {row[0]: dict(zip(fields, row[1:])) for row in confidence_data}
    
    # è·å–æ‰€æœ‰æ ·æœ¬åç§°
    all_samples = set(plddt_dict.keys()) | set(confidence_dict.keys())
    
    # åˆå¹¶æ•°æ®
    merged_data = []
    for sample in sorted(all_samples):
        row = [sample]
        
        # æ·»åŠ  pLDDT æ•°æ®
        row.append(plddt_dict.get(sample))
        
        # æ·»åŠ ç½®ä¿¡åº¦æ•°æ®
        for field in fields:
            row.append(confidence_dict.get(sample, {}).get(field))
        
        # æ·»åŠ è´¨é‡åˆ†ç±»
        plddt = plddt_dict.get(sample)
        ptm = confidence_dict.get(sample, {}).get('ptm')
        
        if plddt is not None and ptm is not None:
            if plddt > 70 and ptm > 0.7:
                quality = 'High'
            elif (plddt > 70 and ptm > 0.5) or (plddt > 50 and ptm > 0.7):
                quality = 'Medium'
            else:
                quality = 'Low'
        else:
            quality = 'Unknown'
        
        row.append(quality)
        merged_data.append(row)
    
    # ä¿å­˜åˆå¹¶ç»“æœ
    with open(output_file, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.writer(csvfile)
        header = ["Sample", "Average_pLDDT"] + [field.upper() for field in fields] + ["Quality"]
        writer.writerow(header)
        writer.writerows(merged_data)


def main():
    parser = argparse.ArgumentParser(
        description="AlphaFold3 æ‰¹é‡åˆ†æå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬åˆ†æ
  python %(prog)s --input_dir /path/to/af3_results --output_dir ./analysis
  
  # æå–ç‰¹å®šå­—æ®µ
  python %(prog)s --input_dir /path/to/af3_results --fields ptm iptm ranking_score
  
  # è¯¦ç»†æ—¥å¿—
  python %(prog)s --input_dir /path/to/af3_results --verbose
        """
    )
    parser.add_argument(
        "--input_dir", 
        required=True, 
        help="AF3 ä¸»è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--output_dir", 
        default="./af3_analysis", 
        help="åˆ†æç»“æœè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./af3_analysisï¼‰"
    )
    parser.add_argument(
        "--fields",
        nargs='+',
        default=['ptm', 'iptm', 'ranking_score'],
        help="è¦æå–çš„ç½®ä¿¡åº¦å­—æ®µï¼ˆé»˜è®¤: ptm iptm ranking_scoreï¼‰"
    )
    parser.add_argument(
        "--verbose", 
        "-v",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—ä¿¡æ¯"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.verbose)
    
    print("ğŸ”„ å¼€å§‹ AlphaFold3 ç»“æœåˆ†æ...\n")
    
    # è¿è¡Œåˆ†æ
    results = analyze_af3_results(
        args.input_dir, 
        args.output_dir, 
        args.fields,
        args.verbose
    )
    
    # ä¿å­˜ç»“æœ
    save_results(results, args.output_dir, args.fields)
    
    print("\nâœ… åˆ†æå®Œæˆï¼")


if __name__ == "__main__":
    main()
